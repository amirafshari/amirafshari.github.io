<!doctype html>
<html lang="en" dir="ltr" class="blog-wrapper blog-post-page plugin-blog plugin-id-default" data-has-hydrated="false">
<head>
<meta charset="UTF-8">
<meta name="generator" content="Docusaurus v3.1.1">
<title data-rh="true">Multimodal Vision-Language Search on Satellite Images | Amir Afshari</title><meta data-rh="true" name="viewport" content="width=device-width,initial-scale=1"><meta data-rh="true" name="twitter:card" content="summary_large_image"><meta data-rh="true" property="og:url" content="https://amirafshari.github.io/blog/remote-sensing-image-search-cbir"><meta data-rh="true" property="og:locale" content="en"><meta data-rh="true" name="docusaurus_locale" content="en"><meta data-rh="true" name="docusaurus_tag" content="default"><meta data-rh="true" name="docsearch:language" content="en"><meta data-rh="true" name="docsearch:docusaurus_tag" content="default"><meta data-rh="true" property="og:title" content="Multimodal Vision-Language Search on Satellite Images | Amir Afshari"><meta data-rh="true" name="description" content="png"><meta data-rh="true" property="og:description" content="png"><meta data-rh="true" property="og:type" content="article"><meta data-rh="true" property="article:published_time" content="2024-05-18T00:00:00.000Z"><meta data-rh="true" property="article:author" content="https://github.com/amirafshari"><meta data-rh="true" property="article:tag" content="Deep Learning,Machine Learning,Computer Vision,Remote Sensing"><link data-rh="true" rel="icon" href="/img/favicon.ico"><link data-rh="true" rel="canonical" href="https://amirafshari.github.io/blog/remote-sensing-image-search-cbir"><link data-rh="true" rel="alternate" href="https://amirafshari.github.io/blog/remote-sensing-image-search-cbir" hreflang="en"><link data-rh="true" rel="alternate" href="https://amirafshari.github.io/blog/remote-sensing-image-search-cbir" hreflang="x-default"><link rel="alternate" type="application/rss+xml" href="/blog/rss.xml" title="Amir Afshari RSS Feed">
<link rel="alternate" type="application/atom+xml" href="/blog/atom.xml" title="Amir Afshari Atom Feed"><link rel="stylesheet" href="/assets/css/styles.8f1f9da0.css">
<script src="/assets/js/runtime~main.c656a66f.js" defer="defer"></script>
<script src="/assets/js/main.dbc06eb6.js" defer="defer"></script>
</head>
<body class="navigation-with-keyboard">
<script>!function(){function t(t){document.documentElement.setAttribute("data-theme",t)}var e=function(){try{return new URLSearchParams(window.location.search).get("docusaurus-theme")}catch(t){}}()||function(){try{return localStorage.getItem("theme")}catch(t){}}();t(null!==e?e:"dark")}(),function(){try{const c=new URLSearchParams(window.location.search).entries();for(var[t,e]of c)if(t.startsWith("docusaurus-data-")){var a=t.replace("docusaurus-data-","data-");document.documentElement.setAttribute(a,e)}}catch(t){}}()</script><div id="__docusaurus"><div role="region" aria-label="Skip to main content"><a class="skipToContent_gu5v" href="#__docusaurus_skipToContent_fallback">Skip to main content</a></div><nav aria-label="Main" class="navbar navbar--fixed-top"><div class="navbar__inner"><div class="navbar__items"><button aria-label="Toggle navigation bar" aria-expanded="false" class="navbar__toggle clean-btn" type="button"><svg width="30" height="30" viewBox="0 0 30 30" aria-hidden="true"><path stroke="currentColor" stroke-linecap="round" stroke-miterlimit="10" stroke-width="2" d="M4 7h22M4 15h22M4 23h22"></path></svg></button><a class="navbar__brand" href="/"><b class="navbar__title text--truncate">Home</b></a><a aria-current="page" class="navbar__item navbar__link navbar__link--active" href="/blog">Blog</a><a class="navbar__item navbar__link" href="/feed">Brain Feed</a></div><div class="navbar__items navbar__items--right"><a href="https://github.com/amirafshari" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Github</a><a href="https://www.linkedin.com/in/amirafshari/" target="_blank" rel="noopener noreferrer" class="navbar__item navbar__link">Linkedin</a><div class="toggle_kWbt colorModeToggle_GwZs"><button class="clean-btn toggleButton_fOL9 toggleButtonDisabled_STpu" type="button" disabled="" title="Switch between dark and light mode (currently dark mode)" aria-label="Switch between dark and light mode (currently dark mode)" aria-live="polite"><svg viewBox="0 0 24 24" width="24" height="24" class="lightToggleIcon_DCeJ"><path fill="currentColor" d="M12,9c1.65,0,3,1.35,3,3s-1.35,3-3,3s-3-1.35-3-3S10.35,9,12,9 M12,7c-2.76,0-5,2.24-5,5s2.24,5,5,5s5-2.24,5-5 S14.76,7,12,7L12,7z M2,13l2,0c0.55,0,1-0.45,1-1s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S1.45,13,2,13z M20,13l2,0c0.55,0,1-0.45,1-1 s-0.45-1-1-1l-2,0c-0.55,0-1,0.45-1,1S19.45,13,20,13z M11,2v2c0,0.55,0.45,1,1,1s1-0.45,1-1V2c0-0.55-0.45-1-1-1S11,1.45,11,2z M11,20v2c0,0.55,0.45,1,1,1s1-0.45,1-1v-2c0-0.55-0.45-1-1-1C11.45,19,11,19.45,11,20z M5.99,4.58c-0.39-0.39-1.03-0.39-1.41,0 c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0s0.39-1.03,0-1.41L5.99,4.58z M18.36,16.95 c-0.39-0.39-1.03-0.39-1.41,0c-0.39,0.39-0.39,1.03,0,1.41l1.06,1.06c0.39,0.39,1.03,0.39,1.41,0c0.39-0.39,0.39-1.03,0-1.41 L18.36,16.95z M19.42,5.99c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06c-0.39,0.39-0.39,1.03,0,1.41 s1.03,0.39,1.41,0L19.42,5.99z M7.05,18.36c0.39-0.39,0.39-1.03,0-1.41c-0.39-0.39-1.03-0.39-1.41,0l-1.06,1.06 c-0.39,0.39-0.39,1.03,0,1.41s1.03,0.39,1.41,0L7.05,18.36z"></path></svg><svg viewBox="0 0 24 24" width="24" height="24" class="darkToggleIcon_DFgp"><path fill="currentColor" d="M9.37,5.51C9.19,6.15,9.1,6.82,9.1,7.5c0,4.08,3.32,7.4,7.4,7.4c0.68,0,1.35-0.09,1.99-0.27C17.45,17.19,14.93,19,12,19 c-3.86,0-7-3.14-7-7C5,9.07,6.81,6.55,9.37,5.51z M12,3c-4.97,0-9,4.03-9,9s4.03,9,9,9s9-4.03,9-9c0-0.46-0.04-0.92-0.1-1.36 c-0.98,1.37-2.58,2.26-4.4,2.26c-2.98,0-5.4-2.42-5.4-5.4c0-1.81,0.89-3.42,2.26-4.4C12.92,3.04,12.46,3,12,3L12,3z"></path></svg></button></div><div class="navbarSearchContainer_IP3a"></div></div></div><div role="presentation" class="navbar-sidebar__backdrop"></div></nav><div id="__docusaurus_skipToContent_fallback" class="main-wrapper mainWrapper_IbdI"><div class="container margin-vert--lg"><div class="row"><aside class="col col--3"><nav class="sidebar_GnOS thin-scrollbar" aria-label="Blog recent posts navigation"><div class="sidebarItemTitle_aARK margin-bottom--md">Recent posts</div><ul class="sidebarItemList_a8Ne clean-list"><li class="sidebarItem_Otbb"><a class="sidebarItemLink_OBo2" href="/blog/remote-sensing-image-search-cbir-becnchmark">Satellite Data Vector Database</a></li><li class="sidebarItem_Otbb"><a aria-current="page" class="sidebarItemLink_OBo2 sidebarItemLinkActive_guiV" href="/blog/remote-sensing-image-search-cbir">Multimodal Vision-Language Search on Satellite Images</a></li><li class="sidebarItem_Otbb"><a class="sidebarItemLink_OBo2" href="/blog/license-plate-detector">Automatic License Plate Detector</a></li><li class="sidebarItem_Otbb"><a class="sidebarItemLink_OBo2" href="/blog/train-custom-object-detector">Train a Custom Object Detector</a></li><li class="sidebarItem_Otbb"><a class="sidebarItemLink_OBo2" href="/blog/spotify-persian-podcasts">Persian Podcasts on Spotify</a></li></ul></nav></aside><main class="col col--7" itemscope="" itemtype="https://schema.org/Blog"><article itemprop="blogPost" itemscope="" itemtype="https://schema.org/BlogPosting"><meta itemprop="description" content="png"><header><h1 class="title_xzwX" itemprop="headline">Multimodal Vision-Language Search on Satellite Images</h1><div class="container_HY9_ margin-vert--md"><time datetime="2024-05-18T00:00:00.000Z" itemprop="datePublished">May 18, 2024</time> Â· <!-- -->3 min read</div><div class="margin-top--md margin-bottom--sm row"><div class="col col--6 authorCol_uEq3"><div class="avatar margin-bottom--sm"><a href="https://github.com/amirafshari" target="_blank" rel="noopener noreferrer" class="avatar__photo-link"><img class="avatar__photo" src="https://avatars.githubusercontent.com/u/17769927?s=400&amp;u=d630f608970a53d00295f2e87e88526b41b7d0b1&amp;v=4" alt="Amir Afshari" itemprop="image"></a><div class="avatar__intro" itemprop="author" itemscope="" itemtype="https://schema.org/Person"><div class="avatar__name"><a href="https://github.com/amirafshari" target="_blank" rel="noopener noreferrer" itemprop="url"><span itemprop="name">Amir Afshari</span></a></div><small class="avatar__subtitle" itemprop="description">Machine Learning Engineer</small></div></div></div></div></header><div id="__blog-post-container" class="markdown" itemprop="articleBody"><p><img alt="png" src="/assets/images/header-7343f4b47de766d8ff193e299f6ba3b8.png" width="800" height="800"></p>
<p>With the rapid advancement of remote sensing technologies, the availability of large-scale satellite image datasets has grown exponentially. These datasets contain invaluable information for various applications, including environmental monitoring, urban planning, and disaster management. However, extracting specific categories of objects, such as identifying all ships within a dataset of one million samples, presents a significant challenge due to the sheer volume of data and the complexity of manual analysis.</p>
<h3 id="solution">Solution</h3>
<p>This task, which is overwhelming for human analysts, can be efficiently addressed using vector search techniques. By leveraging deep learning models to transform images into high-dimensional vectors and utilizing multimodal vision-text models such as CLIP, we can employ nearest neighbor search algorithms to quickly and accurately retrieve relevant images based on their content. For instance, you can search for &quot;red ship floating on the sea&quot; and use it as the query and the system provides you the appropriate instances of the dataset while there is no metadata available. This approach not only enhances the efficiency of data processing but also significantly improves speed of finding specific categories within vast datasets.</p>
<h3 id="good-to-know">Good to know</h3>
<ul>
<li>I did not fine-tune CLIP for remote sensing text-image pairs, but it still works fine.</li>
<li>By fine-tuning, we can enhance the accuracy.</li>
<li>It&#x27;s not a production-level (or even near-production-level) solution, so there is plenty of room for improvement in both speed and accuracy.</li>
<li>We can use vector databases such as Weaviate or Redis instead of a simple Python list.</li>
<li>The dataset is limited to approximately 14,000 samples (a combination of AID, FAIR1M_partial, RESICS_partial, ...).</li>
<li>We can binarize the vectors to improve speed.</li>
<li>You can find the <a href="https://github.com/amirafshari/rs-cbir">code on Github</a></li>
</ul>
<pre><code class="language-python">import matplotlib.pyplot as plt
import numpy as np

import torch
from torchvision import models, transforms
from sklearn.neighbors import NearestNeighbors
import clip


import random
import os
import glob

from PIL import Image
</code></pre>
<pre><code class="language-python">device = torch.device(&quot;cuda&quot; if torch.cuda.is_available() else &quot;cpu&quot;)
device
</code></pre>
<p>device(type=&#x27;cuda&#x27;)</p>
<h3 id="model">Model</h3>
<ul>
<li><a href="https://github.com/mlfoundations/open_clip">https://github.com/mlfoundations/open_clip</a></li>
<li><a href="https://github.com/openai/CLIP/blob/main/README.md">https://github.com/openai/CLIP/blob/main/README.md</a></li>
<li>CLIP</li>
</ul>
<pre><code class="language-python">model, preprocess = clip.load(&quot;ViT-B/32&quot;, device=device)
</code></pre>
<h3 id="image-embedding">Image Embedding</h3>
<pre><code class="language-python"># Walk into directoies to find images and convert them to vectors
image_paths = []
features = []
for root, dirs, files in os.walk(&#x27;datasets/&#x27;):
    for file in files:
        if file.endswith((&quot;.jpg&quot;, &quot;.tif&quot;, &quot;.png&quot;)):
            file_path = os.path.join(root, file)
            image_paths.append(file_path)

            img = Image.open(file_path)
            
            with torch.no_grad():
                feature = model.encode_image(preprocess(img).unsqueeze(0).to(device)).detach().cpu().numpy()
            features.append(feature)


print(len(features), &#x27; Images Found!&#x27;)
f = np.concatenate(features, axis=0)
</code></pre>
<p>14099  Images Found!</p>
<ul>
<li>Took ~ 2m 30s on NVIDIA 3060</li>
</ul>
<h3 id="dataset-visualization">Dataset Visualization</h3>
<pre><code class="language-python"># Here we randomly select an image from dataset as our query image
randompath = image_paths.copy()
random.shuffle(randompath)

n = 50


# Plot query image
rows, columns = 10, 5
fig, axs = plt.subplots(rows, columns, figsize=(20, 50), squeeze=True)


n = 0
for i in range(rows):
    for j in range(columns):

        axs[i][j].imshow(Image.open(randompath[n]))
        axs[i][j].set_title(f&#x27;Instance {n}&#x27;)
        n += 1
plt.show()
</code></pre>
<p><img alt="png" src="/assets/images/dataset-p1-e2d66d066b0a64948364a2a10a9dc25a.png" width="800" height="800">
<img alt="png" src="/assets/images/dataset-p2-bcb1d1ea01ca2ac0a56a0ab13bd586a3.png" width="800" height="800">
<img alt="png" src="/assets/images/dataset-p3-9430d921b48a8fb5396ff293daf428f4.png" width="800" height="800"></p>
<h3 id="nn-search">NN Search</h3>
<pre><code class="language-python"># Text Embedding (Query feature)
query = &#x27;stadium&#x27;
query = clip.tokenize(query).to(device)
query = model.encode_text(query).detach().cpu()
</code></pre>
<pre><code class="language-python"># NN Search
k = 50
neigh = NearestNeighbors(n_neighbors=k, algorithm=&#x27;brute&#x27;)
</code></pre>
<pre><code class="language-python">neigh.fit(f)
distances, indices = neigh.kneighbors(query)
</code></pre>
<pre><code class="language-python">rows, columns = 10, 5
fig, axs = plt.subplots(rows, columns, figsize=(20, 50))


n = 0
for i in range(rows):
    for j in range(columns):

        axs[i][j].imshow(Image.open(image_paths[indices[0][n]]))
        axs[i][j].set_title(f&#x27;Nearest Neighbor {n}&#x27;)
        n += 1
plt.show()
</code></pre>
<p><img alt="png" src="/assets/images/neighbors-1-10fe4921156ecae2d7fe3624a4b4a57a.png" width="800" height="800">
<img alt="png" src="/assets/images/neighbors-2-b98417145899ff7f065caec18062a483.png" width="800" height="800">
<img alt="png" src="/assets/images/neighbors-3-f9f141256e3fb36a9c2b7d89cfa89c43.png" width="800" height="800"></p></div><footer class="row docusaurus-mt-lg blogPostFooterDetailsFull_vccZ"><div class="col"><b>Tags:</b><ul class="tags_aHIs padding--none margin-left--sm"><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/blog/tags/deep-learning">Deep Learning</a></li><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/blog/tags/machine-learning">Machine Learning</a></li><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/blog/tags/computer-vision">Computer Vision</a></li><li class="tag_nwHU"><a class="tag_QDqo tagRegular_RTiO" href="/blog/tags/remote-sensing">Remote Sensing</a></li></ul></div><div class="col margin-top--sm"><a href="https://github.com/amirafshari/amirafshari.github.io/tree/main/blog/2024-05-18-remote-sensing-image-search.md" target="_blank" rel="noopener noreferrer" class="theme-edit-this-page"><svg fill="currentColor" height="20" width="20" viewBox="0 0 40 40" class="iconEdit_NulP" aria-hidden="true"><g><path d="m34.5 11.7l-3 3.1-6.3-6.3 3.1-3q0.5-0.5 1.2-0.5t1.1 0.5l3.9 3.9q0.5 0.4 0.5 1.1t-0.5 1.2z m-29.5 17.1l18.4-18.5 6.3 6.3-18.4 18.4h-6.3v-6.2z"></path></g></svg>Edit this page</a></div></footer></article><nav class="pagination-nav docusaurus-mt-lg" aria-label="Blog post page navigation"><a class="pagination-nav__link pagination-nav__link--prev" href="/blog/remote-sensing-image-search-cbir-becnchmark"><div class="pagination-nav__sublabel">Newer Post</div><div class="pagination-nav__label">Satellite Data Vector Database</div></a><a class="pagination-nav__link pagination-nav__link--next" href="/blog/license-plate-detector"><div class="pagination-nav__sublabel">Older Post</div><div class="pagination-nav__label">Automatic License Plate Detector</div></a></nav></main><div class="col col--2"><div class="tableOfContents_IS5x thin-scrollbar"><ul class="table-of-contents table-of-contents__left-border"><li><a href="#solution" class="table-of-contents__link toc-highlight">Solution</a></li><li><a href="#good-to-know" class="table-of-contents__link toc-highlight">Good to know</a></li><li><a href="#model" class="table-of-contents__link toc-highlight">Model</a></li><li><a href="#image-embedding" class="table-of-contents__link toc-highlight">Image Embedding</a></li><li><a href="#dataset-visualization" class="table-of-contents__link toc-highlight">Dataset Visualization</a></li><li><a href="#nn-search" class="table-of-contents__link toc-highlight">NN Search</a></li></ul></div></div></div></div></div></div>
</body>
</html>